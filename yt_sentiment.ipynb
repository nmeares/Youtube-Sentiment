{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Analysis \n",
    "Proof of concept project for analysing the sentiment of videos return by searching for a key word (i.e. product name). NLP is used to assess the polarity of comments for each video which is then combined with other metrics to return a overall sentiment score.\n",
    "\n",
    "Future additions will integrate a company product list and security identifiers to link companies/ tickers to sentiment scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "1. Create Youtube Data API key as per the instructions [here](https://developers.google.com/youtube/v3/getting-started) \n",
    "\n",
    "2. Create `.env` file containing the key as follows: `YT_API_KEY=[key]`\n",
    "   \n",
    "3. Finally, after installing SpaCy in your environment, ensure the language library is installed by running the below in the terminal:\n",
    "\n",
    "```shell\n",
    "                                        spacy download en_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import database\n",
    "from data_api import youtube\n",
    "from pprint import pprint\n",
    "import os\n",
    "from helpers import dict_search\n",
    "import pandas as pd\n",
    "\n",
    "# Fix for async capability in Jupyter Notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Google Data API Key and Initiate Youtube API Class Instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert this to use the .env file before project completion\n",
    "DEVELOPER_KEY = 'AIzaSyC42N8_Sa6fsoSvG2tFkJNl2XLNYeT0fHk'\n",
    "\n",
    "# Create YouTube Data API object\n",
    "yt = youtube(DEVELOPER_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n",
    "Run a search using the key term, returning the IDs of relevant videos ordered by upload date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'macbook' # Using macbooks as an example\n",
    "\n",
    "# Use search method to retrieve IDs\n",
    "response = yt.search(keyword, order='date')\n",
    "raw_ids = dict_search(response, [\"videoId\"], list_depth=2)\n",
    "ids = [row['videoId'] for row in raw_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>channelId</th>\n",
       "      <th>title</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>commentCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cYhSp8211pI</td>\n",
       "      <td>2022-01-27T14:11:35Z</td>\n",
       "      <td>UCUq3Rn72jfQ-86CaCxj7XzA</td>\n",
       "      <td>UPGRADE your MacBook with THIS!</td>\n",
       "      <td>Created Tech</td>\n",
       "      <td>28</td>\n",
       "      <td>3469</td>\n",
       "      <td>191</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JFlSihaeTfk</td>\n",
       "      <td>2022-01-27T13:32:49Z</td>\n",
       "      <td>UCS9OE6KeXQ54nSMqhRx0_EQ</td>\n",
       "      <td>MacBook Pro 14\" 2021 accessories to create the...</td>\n",
       "      <td>Mobile Fun</td>\n",
       "      <td>28</td>\n",
       "      <td>73</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P7WN5W1xPho</td>\n",
       "      <td>2022-01-27T13:00:12Z</td>\n",
       "      <td>UCYXLvYjC9BniNwRh2AVpbWQ</td>\n",
       "      <td>Nuovi iPhone 14, Macbook, iMac, iPad e NON SOL...</td>\n",
       "      <td>Zorro Giustiziere Tariffe</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VRkF0DOSIM8</td>\n",
       "      <td>2022-01-27T12:40:04Z</td>\n",
       "      <td>UCGcaABa1fX5oPX_3YLgiQ8Q</td>\n",
       "      <td>How to buy Used Macbook ? | Used laptops |  Su...</td>\n",
       "      <td>impression solutions</td>\n",
       "      <td>22</td>\n",
       "      <td>272</td>\n",
       "      <td>82</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ueD_ogy77aI</td>\n",
       "      <td>2022-01-27T12:10:46Z</td>\n",
       "      <td>UCGfluwZUeQNG5HvHuKfSKgw</td>\n",
       "      <td>My $3,200 Upgrade from an Intel MacBook Pro</td>\n",
       "      <td>mobiscrub</td>\n",
       "      <td>26</td>\n",
       "      <td>520</td>\n",
       "      <td>75</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id           publishedAt                 channelId  \\\n",
       "0  cYhSp8211pI  2022-01-27T14:11:35Z  UCUq3Rn72jfQ-86CaCxj7XzA   \n",
       "1  JFlSihaeTfk  2022-01-27T13:32:49Z  UCS9OE6KeXQ54nSMqhRx0_EQ   \n",
       "2  P7WN5W1xPho  2022-01-27T13:00:12Z  UCYXLvYjC9BniNwRh2AVpbWQ   \n",
       "3  VRkF0DOSIM8  2022-01-27T12:40:04Z  UCGcaABa1fX5oPX_3YLgiQ8Q   \n",
       "4  ueD_ogy77aI  2022-01-27T12:10:46Z  UCGfluwZUeQNG5HvHuKfSKgw   \n",
       "\n",
       "                                               title  \\\n",
       "0                    UPGRADE your MacBook with THIS!   \n",
       "1  MacBook Pro 14\" 2021 accessories to create the...   \n",
       "2  Nuovi iPhone 14, Macbook, iMac, iPad e NON SOL...   \n",
       "3  How to buy Used Macbook ? | Used laptops |  Su...   \n",
       "4        My $3,200 Upgrade from an Intel MacBook Pro   \n",
       "\n",
       "                channelTitle categoryId viewCount likeCount commentCount  \n",
       "0               Created Tech         28      3469       191           16  \n",
       "1                 Mobile Fun         28        73         5            0  \n",
       "2  Zorro Giustiziere Tariffe         22        32         8            1  \n",
       "3       impression solutions         22       272        82           16  \n",
       "4                  mobiscrub         26       520        75           16  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve general information for each video\n",
    "raw_stats = yt.video_stats(ids)\n",
    "clean_stats = dict_search(raw_stats, [\n",
    "    \"id\", \n",
    "    \"title\",\n",
    "    \"decription\", \n",
    "    \"channelTitle\",\n",
    "    \"channelId\", \n",
    "    \"categoryId\", \n",
    "    \"viewCount\", \n",
    "    \"likeCount\", \n",
    "    \"commentCount\", \n",
    "    \"publishedAt\"], list_depth=2)\n",
    "stats_df = pd.DataFrame(clean_stats)\n",
    "stats_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve top level comment threads for each video to be used to guage polarity\n",
    "raw_comments = yt.commentThread(ids)\n",
    "comments = dict_search(raw_comments, [\n",
    "    \"videoId\",\n",
    "    \"textDisplay\",\n",
    "    \"publishedAt\"\n",
    "    ], list_depth=2)\n",
    "comments_df = pd.DataFrame(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename id, comments and comment publishedAt columns and merge with stats dataframe\n",
    "stats_df.rename(columns={'id':'videoId'}, inplace=True)\n",
    "comments_df.rename(columns={'textDisplay':'comment', 'publishedAt':'commentDate'}, inplace=True)\n",
    "merged_df = pd.merge(stats_df, comments_df, how='left', on='videoId')\n",
    "merged_df['comment'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve channel stats for each video and merge with other dataframe\n",
    "raw_channelStats = yt.channel(stats_df['channelId'].to_list(), part=\"statistics\")\n",
    "channelStats = dict_search(raw_channelStats, [\n",
    "    \"id\", \n",
    "    \"subscriberCount\", \n",
    "    \"videoCount\"\n",
    "    ], list_depth=2)\n",
    "channel_df = pd.DataFrame(channelStats)\n",
    "\n",
    "# Rename ID column and merge\n",
    "channel_df.rename(columns={'id':'channelId'}, inplace=True)\n",
    "merged_df = pd.merge(merged_df, channel_df, how='left', on='channelId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sentiment object for analysis\n",
    "from analysis import sentiment\n",
    "\n",
    "# Analyse each comment and give polarity score\n",
    "# 1: Positive, 0: Neutral, -1: Negative\n",
    "comment_list = merged_df['comment'].astype(str).to_list()\n",
    "s = sentiment(comment_list)\n",
    "merged_df['comment_polarity'] = s.polarity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "We assess that sentiment can be summarised by: <br>\n",
    "<br>\n",
    "$\\text{Sentiment} = \\dfrac{\\sum\\text{Comment Polarity}}{\\text{Video comment Count}} \\times \\dfrac{\\text{Video Views}}{\\text{Channel Subscribers}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amend data type in count columns from string to integers\n",
    "merged_df[['likeCount', 'viewCount', 'commentCount', 'subscriberCount']] = merged_df[['likeCount', 'viewCount', 'commentCount', 'subscriberCount']].astype(int)\n",
    "\n",
    "df = merged_df.copy()\n",
    "\n",
    "# Polarity scaled by comment count\n",
    "df['comment_polarity'] /= df['commentCount']\n",
    "\n",
    "df['view_sub_ratio'] = df['viewCount'] / df['subscriberCount']\n",
    "df['like_view_ratio'] = df['likeCount'] / df['viewCount']\n",
    "df['comment_view_ratio'] = df['commentCount'] / df['viewCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Grouper for 'commentDate' not 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpyplot\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Sentiment time series\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m time_series \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcommentDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomment_polarity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      5\u001b[0m time_series \u001b[38;5;241m=\u001b[39m (time_series\u001b[38;5;241m-\u001b[39mtime_series\u001b[38;5;241m.\u001b[39mmin())\u001b[38;5;241m/\u001b[39m(time_series\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m-\u001b[39mtime_series\u001b[38;5;241m.\u001b[39mmin())\n\u001b[1;32m      6\u001b[0m time_series\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/yt_sentiment-8_l80sZx/lib/python3.8/site-packages/pandas/core/frame.py:7714\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   7709\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m   7711\u001b[0m \u001b[38;5;66;03m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[1;32m   7712\u001b[0m \u001b[38;5;66;03m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[1;32m   7713\u001b[0m \u001b[38;5;66;03m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[0;32m-> 7714\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   7715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7717\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7720\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7722\u001b[0m \u001b[43m    \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   7723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/yt_sentiment-8_l80sZx/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrouper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_grouper\n\u001b[0;32m--> 882\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/yt_sentiment-8_l80sZx/lib/python3.8/site-packages/pandas/core/groupby/grouper.py:877\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    873\u001b[0m     in_axis, name, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, gpr, obj[gpr]\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    875\u001b[0m         \u001b[38;5;66;03m# non-unique columns; raise here to get the name in the\u001b[39;00m\n\u001b[1;32m    876\u001b[0m         \u001b[38;5;66;03m# exception message\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrouper for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    878\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(name)\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_is_level_reference(gpr, axis\u001b[38;5;241m=\u001b[39maxis):\n",
      "\u001b[0;31mValueError\u001b[0m: Grouper for 'commentDate' not 1-dimensional"
     ]
    }
   ],
   "source": [
    "import matplotlib as pyplot\n",
    "\n",
    "#Sentiment time series\n",
    "time_series = df.groupby('commentDate')['comment_polarity'].mean()\n",
    "time_series = (time_series-time_series.min())/(time_series.max()-time_series.min())\n",
    "time_series.fillna(0, inplace=True)\n",
    "time_series.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Groupby, summing polarity of comments for each video ID\n",
    "df = df.groupby(['videoId','view_sub_ratio', 'like_view_ratio', 'comment_view_ratio', 'subscriberCount', 'publishedAt']).agg({'comment_polarity':['sum']}).reset_index()\n",
    "df.columns = df.columns.droplevel(1)\n",
    "\n",
    "# Create sentiment score\n",
    "df['sentiment'] = df['comment_polarity']*df['view_sub_ratio']\n",
    "\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Price Predictive Power\n",
    "\n",
    "\\*\\*TODO\\*\\*"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17945a635974aec1a967a252cb39291ec8c29ed89f214f92aed5fff0414722b6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('yt_sentiment-8_l80sZx': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
