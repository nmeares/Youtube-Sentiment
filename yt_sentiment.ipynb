{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Analysis \n",
    "Proof of concept project for analysing the sentiment of videos return by searching for a key word (i.e. product name). NLP is used to assess the polarity of comments for each video which is then combined with other metrics to return a overall sentiment score.\n",
    "\n",
    "Future additions will integrate a company product list and security identifiers to link companies/ tickers to sentiment scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies\n",
    "Please ensure SpaCy language library installed by running the below in the terminal:\n",
    "```bash\n",
    "    spacy download en_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import database\n",
    "from data_api import youtube\n",
    "from pprint import pprint\n",
    "import os\n",
    "from helpers import dict_search\n",
    "import pandas as pd\n",
    "\n",
    "# Fix for async capability in Jupyter Notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Google Data API Key and Initiate Youtube API Class Instance\n",
    "1. Create Youtube Data API key as per the instructions at: https://developers.google.com/youtube/v3/getting-started \\\n",
    "\n",
    "2. Create `.env` file containing the key as follows: `YT_API_KEY=[key]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert this to use the .env file before project completion\n",
    "DEVELOPER_KEY = 'AIzaSyC42N8_Sa6fsoSvG2tFkJNl2XLNYeT0fHk'\n",
    "\n",
    "# Create YouTube Data API object\n",
    "yt = youtube(DEVELOPER_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n",
    "Run a search using the key term, returning the IDs of relevant videos ordered by upload date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'macbook'\n",
    "# Use search method to retrieve IDs\n",
    "response = yt.search(keyword, order='date')\n",
    "raw_ids = dict_search(response, [\"videoId\"], list_depth=2)\n",
    "ids = [row['videoId'] for row in raw_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve general information for each video\n",
    "raw_stats = yt.video_stats(ids)\n",
    "clean_stats = dict_search(raw_stats, [\n",
    "    \"id\", \n",
    "    \"title\",\n",
    "    \"decription\", \n",
    "    \"channelTitle\",\n",
    "    \"channelId\", \n",
    "    \"categoryId\", \n",
    "    \"viewCount\", \n",
    "    \"likeCount\", \n",
    "    \"commentCount\", \n",
    "    \"publishedAt\"], list_depth=2)\n",
    "stats_df = pd.DataFrame(clean_stats)\n",
    "stats_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve top level comment threads for each video to be used to guage polarity\n",
    "raw_comments = yt.commentThread(ids)\n",
    "comments = dict_search(raw_comments, [\n",
    "    \"videoId\",\n",
    "    \"textDisplay\"\n",
    "    ], list_depth=2)\n",
    "comments_df = pd.DataFrame(comments)\n",
    "\n",
    "# Rename id column and merge dataframe with stats\n",
    "stats_df.rename(columns={'id':'videoId'}, inplace=True)\n",
    "merged_df = pd.merge(stats_df, comments_df, how='inner', on='videoId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve channel stats for each video and merge with other dataframe\n",
    "raw_channelStats = yt.channel(stats_df['channelId'].to_list(), part=\"statistics\")\n",
    "channelStats = dict_search(raw_channelStats, [\n",
    "    \"id\", \n",
    "    \"subscriberCount\", \n",
    "    \"videoCount\"\n",
    "    ], list_depth=2)\n",
    "channel_df = pd.DataFrame(channelStats)\n",
    "\n",
    "# Rename ID column and merge\n",
    "channel_df.rename(columns={'id':'channelId'}, inplace=True)\n",
    "merged_df = pd.merge(merged_df, channel_df, how='inner', on='channelId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sentiment object for analysis\n",
    "from analysis import sentiment\n",
    "\n",
    "comment_list = merged_df['textDisplay'].to_list()\n",
    "s = sentiment(comment_list)\n",
    "merged_df['comment_polarity'] = s.polarity()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17945a635974aec1a967a252cb39291ec8c29ed89f214f92aed5fff0414722b6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('yt_sentiment-8_l80sZx': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
