{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Analysis \n",
    "Proof of concept project for analysing the sentiment of videos returned by searching for a key word (i.e. product name). \n",
    "\n",
    "Initial implimentation uses NLP to assess the polarity of comments for each video combining this with other metrics to return an overall sentiment score.\n",
    "\n",
    "Future additions will integrate a company product list and security identifiers to link companies/ tickers to sentiment scores, allowing for statistical assessment of it's predictive power with regards to stock price.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "1. Create Youtube Data API key as per the instructions [here](https://developers.google.com/youtube/v3/getting-started) \n",
    "\n",
    "2. Create `.env` file containing the key as follows: `YT_API_KEY=[key]`\n",
    "   \n",
    "3. Finally, after installing SpaCy in your environment, ensure the language library is installed by running the below command in the terminal:\n",
    "\n",
    "```shell\n",
    "                                        spacy download en_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import database\n",
    "from data_api import youtube\n",
    "from helpers import dict_search, min_max_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Google Data API Key and Initiate Youtube API Class Instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import env variables and set API key\n",
    "from dotenv import load_dotenv # Needed to insure .env file imported into jupyter env\n",
    "load_dotenv() \n",
    "\n",
    "DEVELOPER_KEY = os.environ.get('YT_API_KEY')\n",
    "\n",
    "\n",
    "# Create YouTube Data API object\n",
    "yt = youtube(DEVELOPER_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n",
    "Run a search using the key term, returning the IDs of relevant videos ordered by upload date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter keyword below:\n",
    "keyword = 'macbook' # Macbook as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use search method to retrieve IDs\n",
    "response = yt.search(keyword, order='date')\n",
    "raw_ids = dict_search(response, [\"videoId\"], list_depth=2)\n",
    "ids = [row['videoId'] for row in raw_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>channelId</th>\n",
       "      <th>title</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>commentCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kXrdDLwVDkc</td>\n",
       "      <td>2022-02-03T16:15:20Z</td>\n",
       "      <td>UCHFr4p4oy2SluK1bGD0A2OQ</td>\n",
       "      <td>–ó–ê–ú–ï–ù–ê –¢–ï–†–ú–û–ü–ê–°–¢–´ –ù–ê MACBOOK PRO</td>\n",
       "      <td>Osipov Music</td>\n",
       "      <td>23</td>\n",
       "      <td>380</td>\n",
       "      <td>59</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sgeyzFLxvdg</td>\n",
       "      <td>2022-02-03T15:34:56Z</td>\n",
       "      <td>UC_EkhlajM42KLVI6OkCksFg</td>\n",
       "      <td>‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ Macbook Air M1 + OBS Studio Live ‡πÑ‡∏õ Fac...</td>\n",
       "      <td>Undervlog</td>\n",
       "      <td>26</td>\n",
       "      <td>46</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WmahmosgcRc</td>\n",
       "      <td>2022-02-03T15:00:18Z</td>\n",
       "      <td>UCp5VieoKmu5AyNjCgpLIPqg</td>\n",
       "      <td>Ho vinto un MACBOOK PRO da ‚Ç¨2000</td>\n",
       "      <td>RedDani</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gOTC4dTvHPo</td>\n",
       "      <td>2022-02-03T13:13:35Z</td>\n",
       "      <td>UCTx3-1Fka35VriJSmqzpaIw</td>\n",
       "      <td>„ÄêM1Êê≠Ëºâ„Äë70‰∏áÂÜÜË∂Ö„Åà„ÅÆÊñ∞ÂûãMacBook Pro„Åå„Å§„ÅÑ„Å´Êù•„Åæ„Åó„ÅüÔºÅÔºÅÔºÅÔºÅ„Äê16„Ç§„É≥„ÉÅ„Äë</td>\n",
       "      <td>„Ç´„É≥„Çø„ÅÆÂ§ßÂÜíÈô∫„Äê‰∫∫Èñì„Äë</td>\n",
       "      <td>22</td>\n",
       "      <td>4845</td>\n",
       "      <td>885</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RHCn6X-bl0k</td>\n",
       "      <td>2022-02-03T11:04:59Z</td>\n",
       "      <td>UCuw6-7g3ydtDcPJNPwaGkhQ</td>\n",
       "      <td>üíª MacBook üòçüòçüíªunboxing</td>\n",
       "      <td>Dinu &amp; Yashi</td>\n",
       "      <td>19</td>\n",
       "      <td>306</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id           publishedAt                 channelId  \\\n",
       "0  kXrdDLwVDkc  2022-02-03T16:15:20Z  UCHFr4p4oy2SluK1bGD0A2OQ   \n",
       "1  sgeyzFLxvdg  2022-02-03T15:34:56Z  UC_EkhlajM42KLVI6OkCksFg   \n",
       "2  WmahmosgcRc  2022-02-03T15:00:18Z  UCp5VieoKmu5AyNjCgpLIPqg   \n",
       "3  gOTC4dTvHPo  2022-02-03T13:13:35Z  UCTx3-1Fka35VriJSmqzpaIw   \n",
       "4  RHCn6X-bl0k  2022-02-03T11:04:59Z  UCuw6-7g3ydtDcPJNPwaGkhQ   \n",
       "\n",
       "                                               title  channelTitle categoryId  \\\n",
       "0                   –ó–ê–ú–ï–ù–ê –¢–ï–†–ú–û–ü–ê–°–¢–´ –ù–ê MACBOOK PRO  Osipov Music         23   \n",
       "1  ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ Macbook Air M1 + OBS Studio Live ‡πÑ‡∏õ Fac...     Undervlog         26   \n",
       "2                   Ho vinto un MACBOOK PRO da ‚Ç¨2000       RedDani          2   \n",
       "3      „ÄêM1Êê≠Ëºâ„Äë70‰∏áÂÜÜË∂Ö„Åà„ÅÆÊñ∞ÂûãMacBook Pro„Åå„Å§„ÅÑ„Å´Êù•„Åæ„Åó„ÅüÔºÅÔºÅÔºÅÔºÅ„Äê16„Ç§„É≥„ÉÅ„Äë   „Ç´„É≥„Çø„ÅÆÂ§ßÂÜíÈô∫„Äê‰∫∫Èñì„Äë         22   \n",
       "4                              üíª MacBook üòçüòçüíªunboxing  Dinu & Yashi         19   \n",
       "\n",
       "  viewCount likeCount commentCount  \n",
       "0       380        59            5  \n",
       "1        46         9            1  \n",
       "2        67        13            1  \n",
       "3      4845       885          285  \n",
       "4       306        13            2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve general information for each video\n",
    "raw_stats = yt.video_stats(ids)\n",
    "clean_stats = dict_search(raw_stats, [\n",
    "    \"id\", \n",
    "    \"title\",\n",
    "    \"decription\", \n",
    "    \"channelTitle\",\n",
    "    \"channelId\", \n",
    "    \"categoryId\", \n",
    "    \"viewCount\", \n",
    "    \"likeCount\", \n",
    "    \"commentCount\", \n",
    "    \"publishedAt\"], list_depth=2)\n",
    "stats_df = pd.DataFrame(clean_stats)\n",
    "stats_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve top level comment threads for each video to be used to guage polarity\n",
    "raw_comments = yt.commentThread(ids)\n",
    "comments = dict_search(raw_comments, [\n",
    "    \"videoId\",\n",
    "    \"textDisplay\",\n",
    "    \"publishedAt\"\n",
    "    ], list_depth=2)\n",
    "comments_df = pd.DataFrame(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename id, comments and comment publishedAt columns and merge with stats dataframe\n",
    "stats_df.rename(columns={'id':'videoId'}, inplace=True)\n",
    "comments_df.rename(columns={'textDisplay':'comment', 'publishedAt':'commentDate'}, inplace=True)\n",
    "merged_df = pd.merge(stats_df, comments_df, how='left', on='videoId')\n",
    "merged_df['comment'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve channel stats for each video and merge with other dataframe\n",
    "raw_channelStats = yt.channel(stats_df['channelId'].to_list(), part=\"statistics\")\n",
    "channelStats = dict_search(raw_channelStats, [\n",
    "    \"id\", \n",
    "    \"subscriberCount\", \n",
    "    \"videoCount\"\n",
    "    ], list_depth=2)\n",
    "channel_df = pd.DataFrame(channelStats)\n",
    "\n",
    "# Rename ID column and merge\n",
    "channel_df.rename(columns={'id':'channelId'}, inplace=True)\n",
    "merged_df = pd.merge(merged_df, channel_df, how='left', on='channelId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "We assess that sentiment can be summarised by: <br>\n",
    "<br>\n",
    "$\\text{Sentiment} = \\dfrac{\\sum\\text{Comment Polarity}}{\\text{Video comment Count}} \\times \\dfrac{\\text{Video Views}}{\\text{Channel Subscribers}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sentiment object for analysis\n",
    "from analysis import sentiment\n",
    "\n",
    "# Analyse each comment and give polarity score\n",
    "# 1: Positive, 0: Neutral, -1: Negative\n",
    "comment_list = merged_df['comment'].astype(str).to_list()\n",
    "s = sentiment(comment_list)\n",
    "merged_df['comment_polarity'] = s.polarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amend data type in count columns from string to integers\n",
    "merged_df[['likeCount', 'viewCount', 'commentCount', 'subscriberCount']] = merged_df[['likeCount', 'viewCount', 'commentCount', 'subscriberCount']].astype(int)\n",
    "for column in ['publishedAt', 'commentDate']:\n",
    "    merged_df[column] = merged_df[column].astype('datetime64').dt.normalize()\n",
    "\n",
    "df = merged_df.copy()\n",
    "\n",
    "# Polarity scaled by comment count\n",
    "df['comment_polarity'] /= df['commentCount']\n",
    "\n",
    "df['view_sub_ratio'] = df['viewCount'] / df['subscriberCount']\n",
    "df['like_view_ratio'] = df['likeCount'] / df['viewCount']\n",
    "df['comment_view_ratio'] = df['commentCount'] / df['viewCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sentiment time series\n",
    "time_series = df.copy()\n",
    "time_series = time_series.groupby('commentDate').agg(polarity=('comment_polarity','mean'), count = ('commentDate','size')).reset_index()\n",
    "time_series.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'comment_polarity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/share/virtualenvs/yt_sentiment-8_l80sZx/lib/python3.8/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/yt_sentiment-8_l80sZx/lib/python3.8/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/yt_sentiment-8_l80sZx/lib/python3.8/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'comment_polarity'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Normalise comment polarity\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m time_series[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomment_polarity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m min_max_scaler(\u001b[43mtime_series\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcomment_polarity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/yt_sentiment-8_l80sZx/lib/python3.8/site-packages/pandas/core/frame.py:3506\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3506\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3508\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/yt_sentiment-8_l80sZx/lib/python3.8/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'comment_polarity'"
     ]
    }
   ],
   "source": [
    "# Normalise comment polarity\n",
    "time_series['comment_polarity'] = min_max_scaler(time_series['comment_polarity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Groupby, summing polarity of comments for each video ID\n",
    "df = df.groupby(['videoId','view_sub_ratio', 'like_view_ratio', 'comment_view_ratio', 'subscriberCount']).agg({'comment_polarity':['sum']}).reset_index()\n",
    "df.columns = df.columns.droplevel(1)\n",
    "\n",
    "# Create video sentiment score\n",
    "df['sentiment'] = df['comment_polarity']*df['view_sub_ratio']\n",
    "\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Price Predictive Power\n",
    "\n",
    "\\*\\*TODO\\*\\*"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17945a635974aec1a967a252cb39291ec8c29ed89f214f92aed5fff0414722b6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('yt_sentiment-8_l80sZx': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
