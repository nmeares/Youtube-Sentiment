{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Analysis \n",
    "Proof of concept project for analysing the sentiment of videos return by searching for a key word (i.e. product name). NLP is used to assess the polarity of comments for each video which is then combined with other metrics to return a overall sentiment score.\n",
    "\n",
    "Future additions will integrate a company product list and security identifiers to link companies/ tickers to sentiment scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "1. Create Youtube Data API key as per the instructions [here](https://developers.google.com/youtube/v3/getting-started) \n",
    "\n",
    "2. Create `.env` file containing the key as follows: `YT_API_KEY=[key]`\n",
    "   \n",
    "3. Finally, after installing SpaCy in your environment, ensure the language library is installed by running the below in the terminal:\n",
    "\n",
    "```shell\n",
    "                                        spacy download en_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import database\n",
    "from data_api import youtube\n",
    "from pprint import pprint\n",
    "import os\n",
    "from helpers import dict_search\n",
    "import pandas as pd\n",
    "\n",
    "# Fix for async capability in Jupyter Notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Google Data API Key and Initiate Youtube API Class Instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert this to use the .env file before project completion\n",
    "DEVELOPER_KEY = 'AIzaSyC42N8_Sa6fsoSvG2tFkJNl2XLNYeT0fHk'\n",
    "\n",
    "# Create YouTube Data API object\n",
    "yt = youtube(DEVELOPER_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n",
    "Run a search using the key term, returning the IDs of relevant videos ordered by upload date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'macbook' # Using macbooks as an example\n",
    "\n",
    "# Use search method to retrieve IDs\n",
    "response = yt.search(keyword, order='date')\n",
    "raw_ids = dict_search(response, [\"videoId\"], list_depth=2)\n",
    "ids = [row['videoId'] for row in raw_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>channelId</th>\n",
       "      <th>title</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>commentCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cYhSp8211pI</td>\n",
       "      <td>2022-01-27T14:11:35Z</td>\n",
       "      <td>UCUq3Rn72jfQ-86CaCxj7XzA</td>\n",
       "      <td>UPGRADE your MacBook with THIS!</td>\n",
       "      <td>Created Tech</td>\n",
       "      <td>28</td>\n",
       "      <td>3469</td>\n",
       "      <td>191</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JFlSihaeTfk</td>\n",
       "      <td>2022-01-27T13:32:49Z</td>\n",
       "      <td>UCS9OE6KeXQ54nSMqhRx0_EQ</td>\n",
       "      <td>MacBook Pro 14\" 2021 accessories to create the...</td>\n",
       "      <td>Mobile Fun</td>\n",
       "      <td>28</td>\n",
       "      <td>73</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P7WN5W1xPho</td>\n",
       "      <td>2022-01-27T13:00:12Z</td>\n",
       "      <td>UCYXLvYjC9BniNwRh2AVpbWQ</td>\n",
       "      <td>Nuovi iPhone 14, Macbook, iMac, iPad e NON SOL...</td>\n",
       "      <td>Zorro Giustiziere Tariffe</td>\n",
       "      <td>22</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VRkF0DOSIM8</td>\n",
       "      <td>2022-01-27T12:40:04Z</td>\n",
       "      <td>UCGcaABa1fX5oPX_3YLgiQ8Q</td>\n",
       "      <td>How to buy Used Macbook ? | Used laptops |  Su...</td>\n",
       "      <td>impression solutions</td>\n",
       "      <td>22</td>\n",
       "      <td>272</td>\n",
       "      <td>82</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ueD_ogy77aI</td>\n",
       "      <td>2022-01-27T12:10:46Z</td>\n",
       "      <td>UCGfluwZUeQNG5HvHuKfSKgw</td>\n",
       "      <td>My $3,200 Upgrade from an Intel MacBook Pro</td>\n",
       "      <td>mobiscrub</td>\n",
       "      <td>26</td>\n",
       "      <td>520</td>\n",
       "      <td>75</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id           publishedAt                 channelId  \\\n",
       "0  cYhSp8211pI  2022-01-27T14:11:35Z  UCUq3Rn72jfQ-86CaCxj7XzA   \n",
       "1  JFlSihaeTfk  2022-01-27T13:32:49Z  UCS9OE6KeXQ54nSMqhRx0_EQ   \n",
       "2  P7WN5W1xPho  2022-01-27T13:00:12Z  UCYXLvYjC9BniNwRh2AVpbWQ   \n",
       "3  VRkF0DOSIM8  2022-01-27T12:40:04Z  UCGcaABa1fX5oPX_3YLgiQ8Q   \n",
       "4  ueD_ogy77aI  2022-01-27T12:10:46Z  UCGfluwZUeQNG5HvHuKfSKgw   \n",
       "\n",
       "                                               title  \\\n",
       "0                    UPGRADE your MacBook with THIS!   \n",
       "1  MacBook Pro 14\" 2021 accessories to create the...   \n",
       "2  Nuovi iPhone 14, Macbook, iMac, iPad e NON SOL...   \n",
       "3  How to buy Used Macbook ? | Used laptops |  Su...   \n",
       "4        My $3,200 Upgrade from an Intel MacBook Pro   \n",
       "\n",
       "                channelTitle categoryId viewCount likeCount commentCount  \n",
       "0               Created Tech         28      3469       191           16  \n",
       "1                 Mobile Fun         28        73         5            0  \n",
       "2  Zorro Giustiziere Tariffe         22        32         8            1  \n",
       "3       impression solutions         22       272        82           16  \n",
       "4                  mobiscrub         26       520        75           16  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve general information for each video\n",
    "raw_stats = yt.video_stats(ids)\n",
    "clean_stats = dict_search(raw_stats, [\n",
    "    \"id\", \n",
    "    \"title\",\n",
    "    \"decription\", \n",
    "    \"channelTitle\",\n",
    "    \"channelId\", \n",
    "    \"categoryId\", \n",
    "    \"viewCount\", \n",
    "    \"likeCount\", \n",
    "    \"commentCount\", \n",
    "    \"publishedAt\"], list_depth=2)\n",
    "stats_df = pd.DataFrame(clean_stats)\n",
    "stats_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve top level comment threads for each video to be used to guage polarity\n",
    "raw_comments = yt.commentThread(ids)\n",
    "comments = dict_search(raw_comments, [\n",
    "    \"videoId\",\n",
    "    \"textDisplay\",\n",
    "    \"publishedAt\"\n",
    "    ], list_depth=2)\n",
    "comments_df = pd.DataFrame(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename id, comments and comment publishedAt columns and merge with stats dataframe\n",
    "stats_df.rename(columns={'id':'videoId'}, inplace=True)\n",
    "comments_df.rename(columns={'textDisplay':'comment', 'publishedAt':'commentDate'}, inplace=True)\n",
    "merged_df = pd.merge(stats_df, comments_df, how='left', on='videoId')\n",
    "merged_df['comment'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve channel stats for each video and merge with other dataframe\n",
    "raw_channelStats = yt.channel(stats_df['channelId'].to_list(), part=\"statistics\")\n",
    "channelStats = dict_search(raw_channelStats, [\n",
    "    \"id\", \n",
    "    \"subscriberCount\", \n",
    "    \"videoCount\"\n",
    "    ], list_depth=2)\n",
    "channel_df = pd.DataFrame(channelStats)\n",
    "\n",
    "# Rename ID column and merge\n",
    "channel_df.rename(columns={'id':'channelId'}, inplace=True)\n",
    "merged_df = pd.merge(merged_df, channel_df, how='left', on='channelId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sentiment object for analysis\n",
    "from analysis import sentiment\n",
    "\n",
    "# Analyse each comment and give polarity score\n",
    "# 1: Positive, 0: Neutral, -1: Negative\n",
    "comment_list = merged_df['comment'].astype(str).to_list()\n",
    "s = sentiment(comment_list)\n",
    "merged_df['comment_polarity'] = s.polarity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "We assess that sentiment can be summarised by: <br>\n",
    "<br>\n",
    "$\\text{Sentiment} = \\dfrac{\\sum\\text{Comment Polarity}}{\\text{Video comment Count}} \\times \\dfrac{\\text{Video Views}}{\\text{Channel Subscribers}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amend data type in count columns from string to integers\n",
    "merged_df[['likeCount', 'viewCount', 'commentCount', 'subscriberCount']] = merged_df[['likeCount', 'viewCount', 'commentCount', 'subscriberCount']].astype(int)\n",
    "\n",
    "df = merged_df.copy()\n",
    "\n",
    "# Polarity scaled by comment count\n",
    "df['comment_polarity'] /= df['commentCount']\n",
    "\n",
    "df['view_sub_ratio'] = df['viewCount'] / df['subscriberCount']\n",
    "df['like_view_ratio'] = df['likeCount'] / df['viewCount']\n",
    "df['comment_view_ratio'] = df['commentCount'] / df['viewCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpyplot\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Sentiment time series\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m time_series \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      6\u001b[0m time_series \u001b[38;5;241m=\u001b[39m time_series[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommentDate_y\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomment_polarity\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      7\u001b[0m time_series[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommentDate_y\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDatetimeIndex(pd\u001b[38;5;241m.\u001b[39mto_datetime(time_series[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommentDate_y\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdate)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib as pyplot\n",
    "\n",
    "#Sentiment time series\n",
    "\n",
    "time_series = df.copy()\n",
    "time_series['commentDate'] = pd.to_datetime(time_series['commentDate']).dt.date\n",
    "time_series = time_series.groupby('commentDate').agg({'comment_polarity': ['mean']}).reset_index()\n",
    "time_series.columns = time_series.columns.droplevel(1)\n",
    "time_series.set_index(pd.DatetimeIndex(time_series['commentDate']), inplace=True)\n",
    "time_series.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = (time_series-time_series.min())/(time_series.max()-time_series.min())\n",
    "time_series.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Groupby, summing polarity of comments for each video ID\n",
    "df = df.groupby(['videoId','view_sub_ratio', 'like_view_ratio', 'comment_view_ratio', 'subscriberCount', 'publishedAt']).agg({'comment_polarity':['sum']}).reset_index()\n",
    "df.columns = df.columns.droplevel(1)\n",
    "\n",
    "# Create sentiment score\n",
    "df['sentiment'] = df['comment_polarity']*df['view_sub_ratio']\n",
    "\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Price Predictive Power\n",
    "\n",
    "\\*\\*TODO\\*\\*"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17945a635974aec1a967a252cb39291ec8c29ed89f214f92aed5fff0414722b6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('yt_sentiment-8_l80sZx': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
