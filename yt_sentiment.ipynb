{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Analysis \n",
    "Proof of concept project for analysing the sentiment of videos return by searching for a key word (i.e. product name). NLP is used to assess the polarity of comments for each video which is then combined with other metrics to return a overall sentiment score.\n",
    "\n",
    "Future additions will integrate a company product list and security identifiers to link companies/ tickers to sentiment scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "1. Create Youtube Data API key as per the instructions [here](https://developers.google.com/youtube/v3/getting-started) \n",
    "\n",
    "2. Create `.env` file containing the key as follows: `YT_API_KEY=[key]`\n",
    "   \n",
    "3. Finally, after installing SpaCy in your environment, ensure the language library is installed by running the below in the terminal:\n",
    "\n",
    "```shell\n",
    "                                        spacy download en_core_web_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import database\n",
    "from data_api import youtube\n",
    "from pprint import pprint\n",
    "import os\n",
    "from helpers import dict_search, min_max_scaler\n",
    "import pandas as pd\n",
    "\n",
    "# Fix for async capability in Jupyter Notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Google Data API Key and Initiate Youtube API Class Instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert this to use the .env file before project completion\n",
    "DEVELOPER_KEY = 'AIzaSyC42N8_Sa6fsoSvG2tFkJNl2XLNYeT0fHk'\n",
    "\n",
    "# Create YouTube Data API object\n",
    "yt = youtube(DEVELOPER_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n",
    "Run a search using the key term, returning the IDs of relevant videos ordered by upload date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'macbook' # Using macbooks as an example\n",
    "\n",
    "# Use search method to retrieve IDs\n",
    "response = yt.search(keyword, order='date')\n",
    "raw_ids = dict_search(response, [\"videoId\"], list_depth=2)\n",
    "ids = [row['videoId'] for row in raw_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>channelId</th>\n",
       "      <th>title</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>viewCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>commentCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eoR_49F7JB8</td>\n",
       "      <td>2022-01-29T16:08:41Z</td>\n",
       "      <td>UCBVJujdfYisnCWjy_AUgMBQ</td>\n",
       "      <td>MACBOOK at CHEAPEST PRICES üí• ||SECOND HAND MAC...</td>\n",
       "      <td>Rishu's Squad 2.0</td>\n",
       "      <td>22</td>\n",
       "      <td>796</td>\n",
       "      <td>105</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CeCppNN-I9g</td>\n",
       "      <td>2022-01-29T14:33:19Z</td>\n",
       "      <td>UCCkXU_pKTN98ktKl0TnHjBg</td>\n",
       "      <td>Budget APPLE Products For STUDENTS - iPad &amp; Ma...</td>\n",
       "      <td>Ansh Nakwal</td>\n",
       "      <td>28</td>\n",
       "      <td>7693</td>\n",
       "      <td>1335</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06pFsuSxbTM</td>\n",
       "      <td>2022-01-29T13:31:18Z</td>\n",
       "      <td>UCHLmaPy_UYFvQcUp-FdpxRg</td>\n",
       "      <td>‡¥™‡µÜ‡¥ü‡µç‡¥ü‡¥ø‡¥™‡µä‡¥ü‡µç‡¥ü‡¥ø‡¥ï‡µç‡¥ï‡µΩ ft. MacBook Air M1 üî• #Shorts</td>\n",
       "      <td>Sarath'S Neon Tech</td>\n",
       "      <td>28</td>\n",
       "      <td>29306</td>\n",
       "      <td>5586</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WoeQaUC2StA</td>\n",
       "      <td>2022-01-29T13:01:46Z</td>\n",
       "      <td>UCjKcp_NRBj9qJnmHS2mZQ0A</td>\n",
       "      <td>ÈñãÁÆ±ÔΩúMacbook Air M1 UnboxingÔΩúÈÜ´Â≠∏ÁîüÊúÄÈúÄË¶ÅÊôÇÈñìÔºåÂâ™ÁâáÂ•ΩÂø´ÂïäÔΩúÂ∞èÂª¢ÁâáÔΩú...</td>\n",
       "      <td>Choco tv</td>\n",
       "      <td>27</td>\n",
       "      <td>136</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HJQIYmcRQU4</td>\n",
       "      <td>2022-01-29T13:00:07Z</td>\n",
       "      <td>UCyQobySFx_h9oFwsBV0KGdg</td>\n",
       "      <td>Benchmark MacBook Pro 16: M1 Max, 64Gb</td>\n",
       "      <td>Tinh t·∫ø</td>\n",
       "      <td>28</td>\n",
       "      <td>2014</td>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id           publishedAt                 channelId  \\\n",
       "0  eoR_49F7JB8  2022-01-29T16:08:41Z  UCBVJujdfYisnCWjy_AUgMBQ   \n",
       "1  CeCppNN-I9g  2022-01-29T14:33:19Z  UCCkXU_pKTN98ktKl0TnHjBg   \n",
       "2  06pFsuSxbTM  2022-01-29T13:31:18Z  UCHLmaPy_UYFvQcUp-FdpxRg   \n",
       "3  WoeQaUC2StA  2022-01-29T13:01:46Z  UCjKcp_NRBj9qJnmHS2mZQ0A   \n",
       "4  HJQIYmcRQU4  2022-01-29T13:00:07Z  UCyQobySFx_h9oFwsBV0KGdg   \n",
       "\n",
       "                                               title        channelTitle  \\\n",
       "0  MACBOOK at CHEAPEST PRICES üí• ||SECOND HAND MAC...   Rishu's Squad 2.0   \n",
       "1  Budget APPLE Products For STUDENTS - iPad & Ma...         Ansh Nakwal   \n",
       "2      ‡¥™‡µÜ‡¥ü‡µç‡¥ü‡¥ø‡¥™‡µä‡¥ü‡µç‡¥ü‡¥ø‡¥ï‡µç‡¥ï‡µΩ ft. MacBook Air M1 üî• #Shorts  Sarath'S Neon Tech   \n",
       "3  ÈñãÁÆ±ÔΩúMacbook Air M1 UnboxingÔΩúÈÜ´Â≠∏ÁîüÊúÄÈúÄË¶ÅÊôÇÈñìÔºåÂâ™ÁâáÂ•ΩÂø´ÂïäÔΩúÂ∞èÂª¢ÁâáÔΩú...            Choco tv   \n",
       "4             Benchmark MacBook Pro 16: M1 Max, 64Gb             Tinh t·∫ø   \n",
       "\n",
       "  categoryId viewCount likeCount commentCount  \n",
       "0         22       796       105           32  \n",
       "1         28      7693      1335          111  \n",
       "2         28     29306      5586           34  \n",
       "3         27       136         8            1  \n",
       "4         28      2014        63            5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve general information for each video\n",
    "raw_stats = yt.video_stats(ids)\n",
    "clean_stats = dict_search(raw_stats, [\n",
    "    \"id\", \n",
    "    \"title\",\n",
    "    \"decription\", \n",
    "    \"channelTitle\",\n",
    "    \"channelId\", \n",
    "    \"categoryId\", \n",
    "    \"viewCount\", \n",
    "    \"likeCount\", \n",
    "    \"commentCount\", \n",
    "    \"publishedAt\"], list_depth=2)\n",
    "stats_df = pd.DataFrame(clean_stats)\n",
    "stats_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve top level comment threads for each video to be used to guage polarity\n",
    "raw_comments = yt.commentThread(ids)\n",
    "comments = dict_search(raw_comments, [\n",
    "    \"videoId\",\n",
    "    \"textDisplay\",\n",
    "    \"publishedAt\"\n",
    "    ], list_depth=2)\n",
    "comments_df = pd.DataFrame(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename id, comments and comment publishedAt columns and merge with stats dataframe\n",
    "stats_df.rename(columns={'id':'videoId'}, inplace=True)\n",
    "comments_df.rename(columns={'textDisplay':'comment', 'publishedAt':'commentDate'}, inplace=True)\n",
    "merged_df = pd.merge(stats_df, comments_df, how='left', on='videoId')\n",
    "merged_df['comment'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve channel stats for each video and merge with other dataframe\n",
    "raw_channelStats = yt.channel(stats_df['channelId'].to_list(), part=\"statistics\")\n",
    "channelStats = dict_search(raw_channelStats, [\n",
    "    \"id\", \n",
    "    \"subscriberCount\", \n",
    "    \"videoCount\"\n",
    "    ], list_depth=2)\n",
    "channel_df = pd.DataFrame(channelStats)\n",
    "\n",
    "# Rename ID column and merge\n",
    "channel_df.rename(columns={'id':'channelId'}, inplace=True)\n",
    "merged_df = pd.merge(merged_df, channel_df, how='left', on='channelId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sentiment object for analysis\n",
    "from analysis import sentiment\n",
    "\n",
    "# Analyse each comment and give polarity score\n",
    "# 1: Positive, 0: Neutral, -1: Negative\n",
    "comment_list = merged_df['comment'].astype(str).to_list()\n",
    "s = sentiment(comment_list)\n",
    "merged_df['comment_polarity'] = s.polarity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "We assess that sentiment can be summarised by: <br>\n",
    "<br>\n",
    "$\\text{Sentiment} = \\dfrac{\\sum\\text{Comment Polarity}}{\\text{Video comment Count}} \\times \\dfrac{\\text{Video Views}}{\\text{Channel Subscribers}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# amend data type in count columns from string to integers\n",
    "merged_df[['likeCount', 'viewCount', 'commentCount', 'subscriberCount']] = merged_df[['likeCount', 'viewCount', 'commentCount', 'subscriberCount']].astype(int)\n",
    "merged_df[['publishedAt', 'commentDate']] = merged_df[['publishedAt', 'commentDate']].astype('datetime64')\n",
    "\n",
    "df = merged_df.copy()\n",
    "\n",
    "# Polarity scaled by comment count\n",
    "df['comment_polarity'] /= df['commentCount']\n",
    "\n",
    "df['view_sub_ratio'] = df['viewCount'] / df['subscriberCount']\n",
    "df['like_view_ratio'] = df['likeCount'] / df['viewCount']\n",
    "df['comment_view_ratio'] = df['commentCount'] / df['viewCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sentiment time series\n",
    "time_series = df.copy()\n",
    "time_series = time_series.groupby('commentDate').agg(polarity=('comment_polarity','mean'), count = ('commentDate','size')).reset_index()\n",
    "time_series.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise comment polarity\n",
    "time_series['comment_polarity'] = min_max_scaler(time_series['comment_polarity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Groupby, summing polarity of comments for each video ID\n",
    "df = df.groupby(['videoId','view_sub_ratio', 'like_view_ratio', 'comment_view_ratio', 'subscriberCount']).agg({'comment_polarity':['sum']}).reset_index()\n",
    "df.columns = df.columns.droplevel(1)\n",
    "\n",
    "# Create video sentiment score\n",
    "df['sentiment'] = df['comment_polarity']*df['view_sub_ratio']\n",
    "\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock Price Predictive Power\n",
    "\n",
    "\\*\\*TODO\\*\\*"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17945a635974aec1a967a252cb39291ec8c29ed89f214f92aed5fff0414722b6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit ('yt_sentiment-8_l80sZx': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
